'''
bot_listener.py

ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’èªè­˜ã—ã¦ã‚µã‚¦ãƒ³ãƒ‰ã‚’é³´ã‚‰ã—ã€ã‚³ãƒãƒ³ãƒ‰å…¥åŠ›ã‚’å¾…æ©Ÿã™ã‚‹éŸ³å£°èªè­˜ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ã™ã€‚
ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã‚‹ã¨ã‚³ãƒãƒ³ãƒ‰å—ä»˜ãƒ¢ãƒ¼ãƒ‰ã«å…¥ã‚Šã€çµ‚äº†ã‚³ãƒãƒ³ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã‚‹ã¨å¾…æ©Ÿãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚Šã¾ã™ã€‚
éŸ³å£°èªè­˜çµæœã‚’è¿”ã—ã€ChatGPTã«ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã—ã¾ã™ã€‚
'''

import json, time
from pathlib import Path

import queue
import sys
from collections import namedtuple

import sounddevice as sd

from vosk import Model, KaldiRecognizer, SetLogLevel


# from bot_motor_controller import neopixels_face, neopixels_hearing, neopixels_off
from test_bot_voice_synthesizer import notification


# Jsonãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã¨ã‚³ãƒãƒ³ãƒ‰ã®é…åˆ—ã‚’èª­ã¿è¾¼ã‚€
with open(Path("data/command_data.json"), "rb") as f:
    data = json.load(f)

WAKE = data["wake"]
EXIT = data["exit"]

class MicrophoneStream:
    """ãƒã‚¤ã‚¯éŸ³å£°å…¥åŠ›ã®ãŸã‚ã®ã‚¯ãƒ©ã‚¹."""

    def __init__(self, rate, chunk):
        """éŸ³å£°å…¥åŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åˆæœŸåŒ–ã™ã‚‹.

        Args:
           rate (int): ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ (Hz)
           chunk (int): éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹å˜ä½ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ï¼‰
        """
        # ãƒã‚¤ã‚¯å…¥åŠ›ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.rate = rate
        self.chunk = chunk

        # å…¥åŠ›ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¼ï¼ˆãƒãƒƒãƒ•ã‚¡ï¼‰
        self.buff = queue.Queue()

        # ãƒã‚¤ã‚¯éŸ³å£°å…¥åŠ›ã®åˆæœŸåŒ–
        self.input_stream = None

    def open_stream(self):
        """ãƒã‚¤ã‚¯éŸ³å£°å…¥åŠ›ã®é–‹å§‹"""
        self.input_stream = sd.RawInputStream(
            samplerate=self.rate,
            blocksize=self.chunk,
            dtype="int16",
            channels=1,
            callback=self.callback,
        )

    def callback(self, indata, frames, time, status):
        """éŸ³å£°å…¥åŠ›ã®åº¦ã«å‘¼ã³å‡ºã•ã‚Œã‚‹é–¢æ•°."""
        if status:
            print(status, file=sys.stderr)

        # å…¥åŠ›ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¼ã¸ä¿å­˜
        self.buff.put(bytes(indata))

    def generator(self):
        """éŸ³å£°èªè­˜ã«å¿…è¦ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ãŸã‚ã®é–¢æ•°."""
        while True:  # ã‚­ãƒ¥ãƒ¼ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ã¦å–ã‚Šå‡ºã™
            # å…ˆé ­ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            chunk = self.buff.get()
            if chunk is None:
                return
            data = [chunk]

            # ã¾ã ã‚­ãƒ¥ãƒ¼ã«ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã£ã¦ã„ã‚Œã°å…¨ã¦å–å¾—ã™ã‚‹
            while True:
                try:
                    chunk = self.buff.get(block=False)
                    if chunk is None:
                        return
                    data.append(chunk)
                except queue.Empty:
                    break

            # yieldã«ã™ã‚‹ã“ã¨ã§ã‚­ãƒ¥ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’éšæ™‚å–å¾—ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
            yield b"".join(data)

SetLogLevel(-1)  # VOSKèµ·å‹•æ™‚ã®ãƒ­ã‚°è¡¨ç¤ºã‚’æŠ‘åˆ¶

# å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã«åŸºã¥ãã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°ã®æƒ…å ±ã‚’å–å¾—
# sd.default.device = [2, 3]
input_device_info = sd.query_devices(kind="input")
# print(input_device_info)
sample_rate = int(input_device_info["default_samplerate"])
# print(sample_rate)
sample_rate = 16000 # 44100
chunk_size = 8000 # 8820

# ãƒã‚¤ã‚¯å…¥åŠ›ã‚’åˆæœŸåŒ–
mic_stream = MicrophoneStream(sample_rate, chunk_size)

# Voskãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
# model = Model(str(Path("vosk-model-small-ja-0.22").resolve()))
# model = Model(str(Path("vosk-model-ja-0.22").resolve()))
model = Model(lang="ja")

# éŸ³å£°èªè­˜å™¨ã‚’æ§‹ç¯‰
recognizer = KaldiRecognizer(model, sample_rate)

# ãƒã‚¤ã‚¯å…¥åŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŠã‚ˆã³éŸ³å£°èªè­˜å™¨ã‚’ã¾ã¨ã‚ã¦ä¿æŒ
VoskStreamingASR = namedtuple(
    "VoskStreamingASR", ["microphone_stream", "recognizer"]
)
vosk_asr = VoskStreamingASR(mic_stream, recognizer)

def get_asr_result(vosk_asr):
    """éŸ³å£°èªè­˜APIã‚’å®Ÿè¡Œã—ã¦æœ€çµ‚çš„ãªèªè­˜çµæœã‚’å¾—ã‚‹.

    Args:
       vosk_asr (VoskStreamingASR): éŸ³å£°èªè­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

    Returns:
       recog_text (str): éŸ³å£°èªè­˜çµæœ
    """
    mic_stream = vosk_asr.microphone_stream
    mic_stream.open_stream()
    with mic_stream.input_stream:
        audio_generator = mic_stream.generator()
        for content in audio_generator:
            if vosk_asr.recognizer.AcceptWaveform(content):
                recog_result = json.loads(vosk_asr.recognizer.Result())
                recog_text = recog_result["text"].split()
                recog_text = "".join(recog_text)  # ç©ºç™½è¨˜å·ã‚’é™¤å»
                return recog_text
        return None


# ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰å¾…æ©Ÿã‚’listening ã‚³ãƒãƒ³ãƒ‰å¾…æ©Ÿã‚’hearingã¨è¨­å®š
listening = True
hearing = False

# listeningã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦éŸ³å£°èªè­˜ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰èªè­˜ã§hearingãƒ«ãƒ¼ãƒ—ã™ã‚‹
def bot_listen_hear():
    global listening, hearing
    
    # neopixelsã®ç›®ã‚’ç‚¹ç¯
    # neopixels_face()
    if hearing == True: print("ğŸ–¥ï¸ SYSTEM: ","-"*22, "GPTã«è©±ã—ã‹ã‘ã¦ãã ã•ã„","-"*22)
    else: print("ğŸ–¥ï¸ SYSTEM: ","-"*22, "ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰å¾…æ©Ÿä¸­","-"*22)
    
    while listening:
        response = get_asr_result(vosk_asr) # engine()
        print(response)
        if response in WAKE:
            listening = False
            hearing = True
            # neopixels_off()
            notification()
            time.sleep(0.5)
            # neopixels_hearing()
            print("ğŸ–¥ï¸ SYSTEM: ","-"*22, "GPTã«è©±ã—ã‹ã‘ã¦ãã ã•ã„","-"*22)
        elif response.strip() == "":
            continue  # ç©ºç™½ã®å ´åˆã¯ãƒ«ãƒ¼ãƒ—ã‚’ç¶šã‘ã‚‹
        else:
            pass
    
    while hearing:
        response = get_asr_result(vosk_asr) # engine()
        print(response)
        if response in EXIT:
            listening = True
            hearing = False
            # neopixels_off()
            notification()
            time.sleep(0.5)
            # neopixels_hearing()
        elif response.strip() == "":
            continue  # ç©ºç™½ã®å ´åˆã¯ãƒ«ãƒ¼ãƒ—ã‚’ç¶šã‘ã‚‹
        else:
            # neopixels_off()
            notification()
            time.sleep(0.5)
            # neopixels_hearing()
        return response 

if __name__ == "__main__":
    while True:
        response = bot_listen_hear()
        print("response: ",response)
